{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Term Project\n",
    "\n",
    "\n",
    "# To support both python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#location of the Dataset\n",
    "datapath = os.path.join(\"datasets\", \"\")\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"end_to_end_project\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loads a Dataset returns a dataframe\n",
    "def load_tab_data(dataset):\n",
    "    csv_path = os.path.join(datapath, dataset)\n",
    "    return pd.read_csv(csv_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes inputed dataset and averages each 4 seqeunces into a dataframe, then returns the averaged seqeunce dataframe\n",
    "def sequence_data(Tab):\n",
    "    size = Tab.shape[0]\n",
    "    size = int((size)/4)\n",
    "    x=int(0)\n",
    "    i=int(0)\n",
    "    for x in range(0, size):\n",
    "        #Averages and rounds 4 rows by coloum\n",
    "        #This line of code is garbage - .mean fails if the first 3 values of the sequence are NaN\n",
    "        #Will investigate later current Tab doesn't have such an arrangement\n",
    "        Tab.loc[x] = Tab[i:(i+3)].mean()\n",
    "        i = i+4\n",
    "    return Tab.loc[0:x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Takes inputed dataset and adds the pre3diction back to the original tab\n",
    "def Un_sequence_data(Tab,predict):\n",
    "    size = predict.size\n",
    "    x=int(0)\n",
    "    i=int(0)\n",
    "    for x in range(x, size-1):\n",
    "        Tab[\"Chord\"].loc[i] =  predict[x]\n",
    "        Tab[\"Chord\"].loc[i+1] =  predict[x]\n",
    "        Tab[\"Chord\"].loc[i+2] =  predict[x]\n",
    "        Tab[\"Chord\"].loc[i+3] =  predict[x]\n",
    "        i=i+4\n",
    "    return Tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Tab = load_tab_data(\"Training set.csv\")\n",
    "test = load_tab_data(\"Dataset.csv\")\n",
    "\n",
    "#Not needed anymore\n",
    "#Chord_Database = load_tab_data(\"Chords.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tabdata = sequence_data(Tab)\n",
    "testdata = sequence_data(test)\n",
    "\n",
    "\n",
    "#fills the datasets NaN values with 254\n",
    "Tabdata = Tabdata.fillna(254)\n",
    "testdata = testdata.fillna(254)\n",
    "\n",
    "#Writes data to csv- for testing\n",
    "#testdata.to_csv('out.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   0.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   1.5       ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   0.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   3.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   0.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   3.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   3.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   3.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   0.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   3.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   3.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   0.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   3.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "          2.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "          2.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "          2.        , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "        254.        ,   3.        ],\n",
       "       [  1.        ,   3.        ,   2.        ,   0.        ,\n",
       "        254.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "        254.        ,   3.        ],\n",
       "       [  1.        ,   3.        ,   2.        ,   0.        ,\n",
       "        254.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  1.        ,   3.        ,   2.        ,   0.        ,\n",
       "        254.        , 254.        ],\n",
       "       [254.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  1.        ,   3.        ,   2.        ,   0.        ,\n",
       "        254.        , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "          2.        , 254.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   2.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [  3.        ,   2.        ,   0.        ,   0.        ,\n",
       "          2.5       , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "          2.        , 254.        ],\n",
       "       [254.        ,   3.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   1.66666667,   2.        ,   2.        ,\n",
       "        254.        , 254.        ],\n",
       "       [  1.        ,   1.        ,   0.        ,   0.        ,\n",
       "          2.        ,   3.        ],\n",
       "       [254.        ,   2.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  1.        , 254.        , 254.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [  0.        , 254.        , 254.        , 254.        ,\n",
       "          2.        ,   0.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "        254.        ,   3.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   0.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   1.5       ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   0.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   3.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   0.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   3.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   3.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   3.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   0.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   3.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   3.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   0.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   3.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "          2.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "          2.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "          2.        , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "        254.        ,   3.        ],\n",
       "       [  1.        ,   3.        ,   2.        ,   0.        ,\n",
       "        254.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "        254.        ,   3.        ],\n",
       "       [  1.        ,   3.        ,   2.        ,   0.        ,\n",
       "        254.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  0.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  1.        ,   3.        ,   2.        ,   0.        ,\n",
       "        254.        , 254.        ],\n",
       "       [254.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   1.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  1.        ,   3.        ,   2.        ,   0.        ,\n",
       "        254.        , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "          2.        , 254.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   2.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [  3.        ,   2.        ,   0.        ,   0.        ,\n",
       "          2.5       , 254.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "          2.        , 254.        ],\n",
       "       [254.        ,   3.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [254.        ,   1.        ,   0.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [254.        ,   1.66666667,   2.        ,   2.        ,\n",
       "        254.        , 254.        ],\n",
       "       [  1.        ,   1.        ,   0.        ,   0.        ,\n",
       "          2.        ,   3.        ],\n",
       "       [254.        ,   2.        ,   2.        ,   2.        ,\n",
       "          0.        , 254.        ],\n",
       "       [  1.        , 254.        , 254.        ,   2.        ,\n",
       "          3.        , 254.        ],\n",
       "       [  0.        , 254.        , 254.        , 254.        ,\n",
       "          2.        ,   0.        ],\n",
       "       [  3.        ,   3.        ,   0.        ,   0.        ,\n",
       "        254.        ,   3.        ]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_learn = Tabdata[['e','B','G','D','A','E']]\n",
    "Y_learn = Tabdata[['Chord']]\n",
    "\n",
    "\n",
    "#Copy + Paste from Lecture 3 - No idea what this does or how it works\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# A class to select numerical or categorical columns \n",
    "# since Scikit-Learn doesn't handle DataFrames yet\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attribute_names):\n",
    "        self.attribute_names = attribute_names\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        return X[self.attribute_names]\n",
    "    \n",
    "from sklearn.pipeline import Pipeline\n",
    "try:\n",
    "    from sklearn.impute import SimpleImputer # Scikit-Learn 0.20+\n",
    "except ImportError:\n",
    "    from sklearn.preprocessing import Imputer as SimpleImputer\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        (\"select_numeric\", DataFrameSelector([\"e\", \"B\", \"G\", \"D\",\"A\",\"E\"])),\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    ])\n",
    "num_pipeline.fit_transform(Tabdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Again No idea what this does\n",
    "class MostFrequentImputer(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        self.most_frequent_ = pd.Series([X[c].value_counts().index[0] for c in X],\n",
    "                                        index=X.columns)\n",
    "        return self\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.most_frequent_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from sklearn.preprocessing import OrdinalEncoder # just to raise an ImportError if Scikit-Learn < 0.20\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "except ImportError:\n",
    "    from future_encoders import OneHotEncoder # Scikit-Learn < 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import FeatureUnion\n",
    "preprocess_pipeline = FeatureUnion(transformer_list=[\n",
    "        (\"num_pipeline\", num_pipeline)\n",
    "        \n",
    "    ])\n",
    "X_train = preprocess_pipeline.fit_transform(Tabdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = Tabdata[\"Chord\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(gamma=\"auto\")\n",
    "svm_clf.fit(X_train, y_train)\n",
    "X_test = preprocess_pipeline.transform(Tabdata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pred = testdata[['e','B','G','D','A','E']]\n",
    "y_pred = svm_clf.predict(X_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9427272727272727"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\n",
    "svm_scores.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test = load_tab_data(\"Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Un_sequence_data(test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('out.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
